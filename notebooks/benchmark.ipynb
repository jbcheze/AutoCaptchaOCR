{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d2446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148cb9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_from_scratch = \"./ANASTASIIA_JB_THEO_9_B.keras\"\n",
    "model_tc_ocr = \"../ocr/crnn/modele_tcr/trocr_phaseB/checkpoint-396/\"\n",
    "\n",
    "data_for_benchmark = \"../data/1000_images_benchmark/\"\n",
    "data_finetune_model = r\"C:\\Users\\jbche\\OneDrive - Université Paris 1 Panthéon-Sorbonne\\MOSEF\\projets\\webscrapping\\projet\\data\\data_OCR_Captcha-20260117T105614Z-1-001\\finetune_russie\\data_russie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191931ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(data_finetune_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa8ff7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24u.png',\n",
       " '2apx.png',\n",
       " '2ex4z.png',\n",
       " '2gmsg.png',\n",
       " '2k249.png',\n",
       " '2pe8n.png',\n",
       " '2s6x3.png',\n",
       " '2sp.png',\n",
       " '2xn.png',\n",
       " '2xn8g.png',\n",
       " '2xu.png',\n",
       " '34b.png',\n",
       " '35k4a.png',\n",
       " '35xn8.png',\n",
       " '37zs.png',\n",
       " '38m5.png',\n",
       " '39pd2.png',\n",
       " '3dg6b.png',\n",
       " '3e3.png',\n",
       " '3edm.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_for_benchmark)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3548d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in os.listdir(data_for_benchmark) : \n",
    "    if value.startswith(\"captcha\") : \n",
    "        os.remove(os.path.join(data_for_benchmark,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "101ede90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24u.png',\n",
       " '2apx.png',\n",
       " '2ex4z.png',\n",
       " '2gmsg.png',\n",
       " '2k249.png',\n",
       " '2pe8n.png',\n",
       " '2s6x3.png',\n",
       " '2sp.png',\n",
       " '2xn.png',\n",
       " '2xn8g.png',\n",
       " '2xu.png',\n",
       " '34b.png',\n",
       " '35k4a.png',\n",
       " '35xn8.png',\n",
       " '37zs.png',\n",
       " '38m5.png',\n",
       " '39pd2.png',\n",
       " '3dg6b.png',\n",
       " '3e3.png',\n",
       " '3edm.png',\n",
       " '3gga.png',\n",
       " '3hsm.png',\n",
       " '3k775.png',\n",
       " '3kqqk.png',\n",
       " '3nbg.png',\n",
       " '3v5xs.png',\n",
       " '3y2vb.png',\n",
       " '3yxau.png',\n",
       " '42d.png',\n",
       " '437.png',\n",
       " '43a3z.png',\n",
       " '452s.png',\n",
       " '482.png',\n",
       " '494.png',\n",
       " '4ce54.png',\n",
       " '4cn2.png',\n",
       " '4csm.png',\n",
       " '4g2zq.png',\n",
       " '4gk8.png',\n",
       " '4hcxz.png',\n",
       " '4hv.png',\n",
       " '4md.png',\n",
       " '4py7.png',\n",
       " '4sxp.png',\n",
       " '4x24.png',\n",
       " '4y3u.png',\n",
       " '4y9uz.png',\n",
       " '4zd5.png',\n",
       " '5.png',\n",
       " '52e.png',\n",
       " '52qac.png',\n",
       " '53y.png',\n",
       " '599xz.png',\n",
       " '59dg.png',\n",
       " '5bnvd.png',\n",
       " '5c3eg.png',\n",
       " '5d5p.png',\n",
       " '5d6na.png',\n",
       " '5eb7.png',\n",
       " '5qg5y.png',\n",
       " '5s5h.png',\n",
       " '5uh.png',\n",
       " '5usp.png',\n",
       " '5yzn.png',\n",
       " '637zp.png',\n",
       " '65s.png',\n",
       " '67ky.png',\n",
       " '68cu9.png',\n",
       " '697.png',\n",
       " '6dq2.png',\n",
       " '6eeu2.png',\n",
       " '6n3mh.png',\n",
       " '6pe9c.png',\n",
       " '6vk2h.png',\n",
       " '6yae.png',\n",
       " '6z6.png',\n",
       " '6zh3.png',\n",
       " '726bz.png',\n",
       " '72h.png',\n",
       " '76y.png',\n",
       " '78q.png',\n",
       " '797ke.png',\n",
       " '79c.png',\n",
       " '7cd8x.png',\n",
       " '7cy.png',\n",
       " '7eeh.png',\n",
       " '7g8y.png',\n",
       " '7h2bg.png',\n",
       " '7hc4k.png',\n",
       " '7kaqn.png',\n",
       " '7p5.png',\n",
       " '7q2.png',\n",
       " '7xv.png',\n",
       " '86q.png',\n",
       " '876.png',\n",
       " '877vu.png',\n",
       " '89h.png',\n",
       " '8as.png',\n",
       " '8c2.png',\n",
       " '8dx.png',\n",
       " '8e9z.png',\n",
       " '8h4.png',\n",
       " '8hm.png',\n",
       " '8ku.png',\n",
       " '8pc.png',\n",
       " '8pq6e.png',\n",
       " '8s8xy.png',\n",
       " '8uz.png',\n",
       " '8xd.png',\n",
       " '8xp.png',\n",
       " '935.png',\n",
       " '93ss.png',\n",
       " '94g.png',\n",
       " '95kd.png',\n",
       " '97b7.png',\n",
       " '98u.png',\n",
       " '9any.png',\n",
       " '9be.png',\n",
       " '9bg.png',\n",
       " '9d5d5.png',\n",
       " '9es6.png',\n",
       " '9k3.png',\n",
       " '9kq.png',\n",
       " '9kvz.png',\n",
       " '9mnmb.png',\n",
       " '9n3g.png',\n",
       " '9p4.png',\n",
       " 'a27n5.png',\n",
       " 'a2z.png',\n",
       " 'a4kvs.png',\n",
       " 'a59d.png',\n",
       " 'a7v.png',\n",
       " 'aa7.png',\n",
       " 'aac8.png',\n",
       " 'abb.png',\n",
       " 'ada4.png',\n",
       " 'adgsc.png',\n",
       " 'aey56.png',\n",
       " 'avb99.png',\n",
       " 'ax5.png',\n",
       " 'aydkq.png',\n",
       " 'b5p.png',\n",
       " 'b7xs.png',\n",
       " 'b8uc.png',\n",
       " 'bb95.png',\n",
       " 'bcn.png',\n",
       " 'bebd.png',\n",
       " 'bgd6c.png',\n",
       " 'bgh.png',\n",
       " 'bkpy8.png',\n",
       " 'bmyz3.png',\n",
       " 'bn7bm.png',\n",
       " 'bpa.png',\n",
       " 'bx7p.png',\n",
       " 'byhq.png',\n",
       " 'bz8p.png',\n",
       " 'bzh.png',\n",
       " 'bzks.png',\n",
       " 'c3vq.png',\n",
       " 'c4x.png',\n",
       " 'cam.png',\n",
       " 'cuc.png',\n",
       " 'd3ey.png',\n",
       " 'd59n.png',\n",
       " 'dsm.png',\n",
       " 'dvn.png',\n",
       " 'dxy.png',\n",
       " 'dzpk.png',\n",
       " 'e3sdk.png',\n",
       " 'e7k.png',\n",
       " 'ehx.png',\n",
       " 'enb.png',\n",
       " 'g35.png',\n",
       " 'g4b3c.png',\n",
       " 'g4qys.png',\n",
       " 'gcv.png',\n",
       " 'gmdu.png',\n",
       " 'gvmh6.png',\n",
       " 'h4dd.png',\n",
       " 'havk9.png',\n",
       " 'hbq93.png',\n",
       " 'he8am.png',\n",
       " 'hgg.png',\n",
       " 'hm9vs.png',\n",
       " 'hsxa8.png',\n",
       " 'huv66.png',\n",
       " 'hvy3.png',\n",
       " 'hy82k.png',\n",
       " 'k.png',\n",
       " 'k473.png',\n",
       " 'k7kc.png',\n",
       " 'k7xeu.png',\n",
       " 'k863.png',\n",
       " 'k8d.png',\n",
       " 'kasx7.png',\n",
       " 'kb3.png',\n",
       " 'kd73e.png',\n",
       " 'kk7q3.png',\n",
       " 'kkn.png',\n",
       " 'ks2k.png',\n",
       " 'ksk6.png',\n",
       " 'kv5y6.png',\n",
       " 'kxmga.png',\n",
       " 'kxv43.png',\n",
       " 'kz4.png',\n",
       " 'm24e.png',\n",
       " 'm3h7.png',\n",
       " 'm58e.png',\n",
       " 'm6s.png',\n",
       " 'm9q.png',\n",
       " 'ma7.png',\n",
       " 'mbcdm.png',\n",
       " 'md33n.png',\n",
       " 'mehq.png',\n",
       " 'mev.png',\n",
       " 'mhqgc.png',\n",
       " 'mk4.png',\n",
       " 'ms3.png',\n",
       " 'muv.png',\n",
       " 'mzk.png',\n",
       " 'n4ke.png',\n",
       " 'nea.png',\n",
       " 'nhx.png',\n",
       " 'nks.png',\n",
       " 'nnm.png',\n",
       " 'p46.png',\n",
       " 'p6c.png',\n",
       " 'p6qm4.png',\n",
       " 'p7n.png',\n",
       " 'pbbh7.png',\n",
       " 'pkb.png',\n",
       " 'pkz.png',\n",
       " 'pm46.png',\n",
       " 'pmub.png',\n",
       " 'pnp.png',\n",
       " 'pnx.png',\n",
       " 'pp5c7.png',\n",
       " 'ppvgb.png',\n",
       " 'pu4ph.png',\n",
       " 'puys.png',\n",
       " 'pv3.png',\n",
       " 'pvp78.png',\n",
       " 'pysz.png',\n",
       " 'pyxs.png',\n",
       " 'q3yn.png',\n",
       " 'q9d.png',\n",
       " 'qey.png',\n",
       " 'qez3.png',\n",
       " 'qhn.png',\n",
       " 'qmeau.png',\n",
       " 'qmxxz.png',\n",
       " 'qn6.png',\n",
       " 'qsz6.png',\n",
       " 'qyp.png',\n",
       " 's2b.png',\n",
       " 's38.png',\n",
       " 's4sy.png',\n",
       " 'sasg7.png',\n",
       " 'sexa.png',\n",
       " 'sm3p.png',\n",
       " 'ssnzh.png',\n",
       " 'u5a.png',\n",
       " 'u5dd.png',\n",
       " 'u65.png',\n",
       " 'u7vp.png',\n",
       " 'u9g.png',\n",
       " 'uebd.png',\n",
       " 'uez.png',\n",
       " 'uv8.png',\n",
       " 'v7y.png',\n",
       " 'vdk6.png',\n",
       " 'vn3k.png',\n",
       " 'vun.png',\n",
       " 'vxa5.png',\n",
       " 'vxe.png',\n",
       " 'x3ne.png',\n",
       " 'x625.png',\n",
       " 'x6v9p.png',\n",
       " 'x89.png',\n",
       " 'x8z.png',\n",
       " 'xae.png',\n",
       " 'xg65.png',\n",
       " 'xqv.png',\n",
       " 'xvu.png',\n",
       " 'xz833.png',\n",
       " 'xzn.png',\n",
       " 'y2xv.png',\n",
       " 'y3y.png',\n",
       " 'y6kn.png',\n",
       " 'y8x.png',\n",
       " 'y9bd.png',\n",
       " 'ydds.png',\n",
       " 'yexb.png',\n",
       " 'yn5q.png',\n",
       " 'ysec.png',\n",
       " 'yxu.png',\n",
       " 'yyb.png',\n",
       " 'yzn.png',\n",
       " 'z4px.png',\n",
       " 'z6h9z.png',\n",
       " 'zd2m.png',\n",
       " 'zd9p9.png',\n",
       " 'zdkm.png',\n",
       " 'ze79.png',\n",
       " 'zeyp.png',\n",
       " 'zgh.png',\n",
       " 'znm8e.png',\n",
       " 'zxa.png',\n",
       " 'zz3u.png']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_for_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61922b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers en commun : 162\n"
     ]
    }
   ],
   "source": [
    "files_benchmark = set(os.listdir(data_for_benchmark))\n",
    "files_finetune = set(os.listdir(data_finetune_model))\n",
    "\n",
    "common_files = files_benchmark.intersection(files_finetune)\n",
    "\n",
    "print(\"Nombre de fichiers en commun :\", len(common_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efe14fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'4y3u.png', '8c2.png', '53y.png', 'm3h7.png', 'pvp78.png', 's4sy.png', 'kb3.png', 'huv66.png', 'k473.png', '876.png', 'mbcdm.png', '7p5.png', '34b.png', 'bkpy8.png', '52qac.png', 'kz4.png', 'mev.png', 'abb.png', '2apx.png', '797ke.png', '9any.png', '38m5.png', '7cy.png', '935.png', '6eeu2.png', '8e9z.png', '5qg5y.png', '697.png', '8ku.png', '43a3z.png', 'bzks.png', 'kasx7.png', '2s6x3.png', 'a27n5.png', '7q2.png', 'pnp.png', 'm6s.png', '8hm.png', '89h.png', '4hv.png', '39pd2.png', '9d5d5.png', '5usp.png', 'bz8p.png', '6dq2.png', 'a7v.png', '8xp.png', '4gk8.png', '2pe8n.png', 'y8x.png', '5c3eg.png', '86q.png', 'pv3.png', '9bg.png', '599xz.png', 'pkb.png', 'yn5q.png', 'xvu.png', 'pu4ph.png', '5d5p.png', '6pe9c.png', 'bgh.png', '8s8xy.png', '7kaqn.png', 'puys.png', '4md.png', 'pbbh7.png', 'yyb.png', '9es6.png', '3gga.png', 'k7kc.png', '6n3mh.png', 'kv5y6.png', 'aa7.png', '24u.png', 'kxv43.png', '78q.png', '4csm.png', 'ksk6.png', '2xn8g.png', '72h.png', 'y3y.png', '4hcxz.png', 'aydkq.png', 'zd9p9.png', 'hy82k.png', 'k8d.png', 'yexb.png', '4y9uz.png', '5s5h.png', 'pkz.png', 'qmeau.png', '9kq.png', '2xu.png', 'ysec.png', 'qmxxz.png', '93ss.png', '95kd.png', 'm58e.png', '494.png', '3nbg.png', '4x24.png', 'q9d.png', '9k3.png', 'bb95.png', '37zs.png', 'b7xs.png', '5bnvd.png', '3hsm.png', 'm24e.png', 'pyxs.png', '68cu9.png', '5eb7.png', 'xz833.png', '52e.png', 'y6kn.png', '59dg.png', 'q3yn.png', '5yzn.png', 'y2xv.png', '6yae.png', 'a59d.png', 'z6h9z.png', '7h2bg.png', 'xzn.png', 's38.png', '3yxau.png', 'avb99.png', 'hvy3.png', 'k863.png', 'kd73e.png', '67ky.png', '79c.png', 'byhq.png', '35xn8.png', '4ce54.png', '7xv.png', '8dx.png', 'mhqgc.png', 'sexa.png', 'sm3p.png', 'k7xeu.png', '6z6.png', 'pysz.png', 'ms3.png', '8pc.png', '6vk2h.png', 'm9q.png', '637zp.png', '98u.png', '3edm.png', '4py7.png', '9n3g.png', 'hsxa8.png', '76y.png', 'ppvgb.png', '8xd.png', '9kvz.png', '2gmsg.png', '4cn2.png', '7hc4k.png', 'kkn.png'}\n"
     ]
    }
   ],
   "source": [
    "print(common_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de767305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers uniques : 147\n",
      "Dossier créé : ../data/data_benchmark_unique\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# chemins\n",
    "src_dir = data_for_benchmark\n",
    "other_dir = data_finetune_model\n",
    "out_dir = \"../data/data_benchmark_unique\"\n",
    "\n",
    "# créer le dossier de sortie\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# listes de fichiers\n",
    "files_benchmark = set(os.listdir(src_dir))\n",
    "files_finetune = set(os.listdir(other_dir))\n",
    "\n",
    "# fichiers uniques\n",
    "unique_files = files_benchmark - files_finetune\n",
    "\n",
    "print(\"Nombre de fichiers uniques :\", len(unique_files))\n",
    "\n",
    "# copier les fichiers uniques\n",
    "for f in unique_files:\n",
    "    src_path = os.path.join(src_dir, f)\n",
    "    dst_path = os.path.join(out_dir, f)\n",
    "    \n",
    "    if os.path.isfile(src_path):\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "print(\"Dossier créé :\", out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c484eb-38a9-4aec-b463-113668991c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy opencv-python pillow sentencepiece transformers torch\n",
    "!pip install tensorflow keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b13133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Mosef\\webscrapping\\projet\\Captchas-Automatic-Resolution\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Mosef\\webscrapping\\projet\\Captchas-Automatic-Resolution\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|█| 362/362 [00:01<00:00, 297.32it/s, Mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ OCR BENCHMARK ================\n",
      "Dataset size: 147 images\n",
      "\n",
      "--- CRNN (from scratch) ---\n",
      "Exact Match : 0.3810\n",
      "CER         : 0.2523\n",
      "Total time  : 213.658 s\n",
      "Time/image  : 1.453457 s\n",
      "\n",
      "--- TrOCR (fine-tuned) ---\n",
      "Exact Match : 0.3946\n",
      "CER         : 0.2667\n",
      "Total time  : 87.697 s\n",
      "Time/image  : 0.596581 s\n",
      "\n",
      "=========== GAIN TROCR vs CRNN ===========\n",
      "Accuracy gain (Exact) : +0.0136\n",
      "CER gain              : -0.0144\n",
      "Speed ratio           : x0.41 slower\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# OCR BENCHMARK — CRNN vs TrOCR\n",
    "# =========================================================\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import cv2\n",
    "import torch\n",
    "from transformers import VisionEncoderDecoderModel, TrOCRProcessor\n",
    "\n",
    "# ======================\n",
    "# CONFIG\n",
    "# ======================\n",
    "IMG_DIR = \"../data/data_benchmark_unique\"\n",
    "\n",
    "# ---- CRNN model\n",
    "MODEL_CRNN_PATH = r\"C:\\Mosef\\webscrapping\\projet\\Captchas-Automatic-Resolution\\models\\ANASTASIIA_JB_THEO_9B2_PLUS_SITE.keras\"\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = 200, 50\n",
    "CHARS = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "NUM_CHARS = len(CHARS)\n",
    "\n",
    "# ---- TrOCR model\n",
    "MODEL_TROCR_PATH = \"../ocr/crnn/modele_tcr/trocr_phaseB/checkpoint-396/\"\n",
    "BASE_TROCR = \"microsoft/trocr-small-printed\"\n",
    "MAX_LEN = 6\n",
    "\n",
    "# ======================\n",
    "# LEVENSHTEIN + METRICS\n",
    "# ======================\n",
    "def levenshtein(a, b):\n",
    "    n, m = len(a), len(b)\n",
    "    if n == 0: return m\n",
    "    if m == 0: return n\n",
    "    prev = list(range(m + 1))\n",
    "    for i in range(1, n + 1):\n",
    "        cur = [i] + [0] * m\n",
    "        for j in range(1, m + 1):\n",
    "            cost = 0 if a[i-1] == b[j-1] else 1\n",
    "            cur[j] = min(prev[j] + 1, cur[j-1] + 1, prev[j-1] + cost)\n",
    "        prev = cur\n",
    "    return prev[m]\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    exact = np.mean([p == l for p, l in zip(preds, labels)])\n",
    "    edits, chars = 0, 0\n",
    "    for p, l in zip(preds, labels):\n",
    "        edits += levenshtein(p, l)\n",
    "        chars += len(l)\n",
    "    cer = edits / max(1, chars)\n",
    "    return exact, cer\n",
    "\n",
    "# ======================\n",
    "# CRNN MODEL (CTC)\n",
    "# ======================\n",
    "class CTCLayer(layers.Layer):\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch = tf.shape(y_true)[0]\n",
    "        input_len = tf.fill([batch], tf.shape(y_pred)[1])\n",
    "        label_len = tf.reduce_sum(tf.cast(y_true >= 0, tf.int32), axis=1)\n",
    "        sparse = tf.keras.backend.ctc_label_dense_to_sparse(y_true, label_len)\n",
    "        loss = tf.nn.ctc_loss(\n",
    "            labels=sparse,\n",
    "            logits=tf.math.log(tf.transpose(y_pred, [1, 0, 2]) + 1e-8),\n",
    "            label_length=label_len,\n",
    "            logit_length=input_len,\n",
    "            blank_index=NUM_CHARS\n",
    "        )\n",
    "        self.add_loss(tf.reduce_mean(loss))\n",
    "        return y_pred\n",
    "\n",
    "model_crnn = keras.models.load_model(\n",
    "    MODEL_CRNN_PATH,\n",
    "    custom_objects={\"CTCLayer\": CTCLayer},\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "infer_model = keras.Model(\n",
    "    model_crnn.inputs[0],\n",
    "    model_crnn.layers[-2].output\n",
    ")\n",
    "\n",
    "num_to_char = layers.StringLookup(\n",
    "    vocabulary=list(CHARS),\n",
    "    mask_token=None,\n",
    "    invert=True\n",
    ")\n",
    "\n",
    "def load_image(path):\n",
    "    img = tf.io.decode_image(\n",
    "        tf.io.read_file(path),\n",
    "        channels=1,\n",
    "        expand_animations=False\n",
    "    )\n",
    "    img = tf.image.resize(\n",
    "        tf.image.convert_image_dtype(img, tf.float32),\n",
    "        [IMG_HEIGHT, IMG_WIDTH]\n",
    "    )\n",
    "    img = tf.transpose(img, [1, 0, 2])\n",
    "    return img\n",
    "\n",
    "def predict_crnn(path):\n",
    "    img = load_image(path)\n",
    "    img = tf.expand_dims(img, 0)\n",
    "\n",
    "    pred = infer_model(img, training=False)\n",
    "\n",
    "    decoded, _ = tf.keras.backend.ctc_decode(\n",
    "        pred,\n",
    "        input_length=np.ones(pred.shape[0]) * pred.shape[1],\n",
    "        greedy=True\n",
    "    )\n",
    "\n",
    "    seq = decoded[0][0].numpy()\n",
    "    seq = seq[(seq >= 0) & (seq < NUM_CHARS)]\n",
    "    seq = seq + 1  # fix StringLookup\n",
    "\n",
    "    text = \"\".join(num_to_char(seq).numpy().astype(str))\n",
    "    return text.lower()\n",
    "\n",
    "# ======================\n",
    "# TROCR MODEL\n",
    "# ======================\n",
    "processor = TrOCRProcessor.from_pretrained(BASE_TROCR)\n",
    "model_trocr = VisionEncoderDecoderModel.from_pretrained(MODEL_TROCR_PATH)\n",
    "\n",
    "def predict_trocr(path):\n",
    "    img = cv2.imread(path)\n",
    "    pixel_values = processor(images=img, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model_trocr.generate(pixel_values, max_length=MAX_LEN)\n",
    "\n",
    "    return processor.batch_decode(generated_ids, skip_special_tokens=True)[0].lower()\n",
    "\n",
    "# ======================\n",
    "# DATASET\n",
    "# ======================\n",
    "files = sorted(os.listdir(IMG_DIR))\n",
    "\n",
    "def get_label(filename):\n",
    "    return os.path.splitext(filename)[0].lower()\n",
    "\n",
    "labels = [get_label(f) for f in files]\n",
    "\n",
    "# ======================\n",
    "# BENCHMARK\n",
    "# ======================\n",
    "preds_crnn = []\n",
    "preds_trocr = []\n",
    "\n",
    "# ---- CRNN timing\n",
    "t0 = time.time()\n",
    "for f in files:\n",
    "    preds_crnn.append(predict_crnn(os.path.join(IMG_DIR, f)))\n",
    "t_crnn = time.time() - t0\n",
    "\n",
    "# ---- TrOCR timing\n",
    "t0 = time.time()\n",
    "for f in files:\n",
    "    preds_trocr.append(predict_trocr(os.path.join(IMG_DIR, f)))\n",
    "t_trocr = time.time() - t0\n",
    "\n",
    "# ======================\n",
    "# METRICS\n",
    "# ======================\n",
    "exact_crnn, cer_crnn = compute_metrics(preds_crnn, labels)\n",
    "exact_trocr, cer_trocr = compute_metrics(preds_trocr, labels)\n",
    "\n",
    "n = len(files)\n",
    "\n",
    "print(\"\\n================ OCR BENCHMARK ================\")\n",
    "print(f\"Dataset size: {n} images\")\n",
    "\n",
    "print(\"\\n--- CRNN (from scratch) ---\")\n",
    "print(f\"Exact Match : {exact_crnn:.4f}\")\n",
    "print(f\"CER         : {cer_crnn:.4f}\")\n",
    "print(f\"Total time  : {t_crnn:.3f} s\")\n",
    "print(f\"Time/image  : {t_crnn/n:.6f} s\")\n",
    "\n",
    "print(\"\\n--- TrOCR (fine-tuned) ---\")\n",
    "print(f\"Exact Match : {exact_trocr:.4f}\")\n",
    "print(f\"CER         : {cer_trocr:.4f}\")\n",
    "print(f\"Total time  : {t_trocr:.3f} s\")\n",
    "print(f\"Time/image  : {t_trocr/n:.6f} s\")\n",
    "\n",
    "print(\"\\n=========== GAIN TROCR vs CRNN ===========\")\n",
    "print(f\"Accuracy gain (Exact) : {exact_trocr - exact_crnn:+.4f}\")\n",
    "print(f\"CER gain              : {cer_crnn - cer_trocr:+.4f}\")\n",
    "print(f\"Speed ratio           : x{t_trocr / t_crnn:.2f} slower\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (OCR)",
   "language": "python",
   "name": "venv-ocr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
